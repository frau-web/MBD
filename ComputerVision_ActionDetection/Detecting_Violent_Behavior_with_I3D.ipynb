{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Detecting Violent Behavior with I3D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo2rOqfZ9RpB"
      },
      "source": [
        "# Detecting Violent Behavior with I3D\n",
        "\n",
        "Gluon CV is a model zoo containing a wide variety of pre-trained computer vision models, among others a useful implementation of I3D, an action detection model. This particular model is trained on Kinetics400, which, following the words of the GluonCV documentation (https://cv.gluon.ai/build/examples_action_recognition/finetune_custom.html): \n",
        "\n",
        ">[Kinetics400](https://deepmind.com/research/open-source/kinetics)  is an action recognition dataset\n",
        "of realistic action videos, collected from YouTube. With 306,245 short trimmed videos\n",
        "from 400 action categories, it is one of the largest and most widely used dataset in the research\n",
        "community for benchmarking state-of-the-art video action recognition models.\n",
        "\n",
        "The task at hand here is to fine-tune I3D on a custom dataset. This dataset contains mostly CCTV recordings, some classified with `0`, corresponding to regular, non-violent behavior, and others classified with `1`, corresponding to violent behavior which a hypothetical security agent should take into account. To carry out this fine-tuning, GluonCV's implementation using `mxnet` is employed, as it is fairly well documented and easy to use.\n",
        "\n",
        "## 1. Environment Set-Up\n",
        "Let us begin by installing and importing all necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyRUB9iw_PXh",
        "outputId": "58b1ce4a-374d-4746-880e-4b8b5921d24e"
      },
      "source": [
        "!pip install -U mxnet-cu101==1.7.0\n",
        "!pip install --upgrade gluoncv\n",
        "!pip install gluoncv[full]\n",
        "!pip3 install opencv-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet-cu101==1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/26/9655677b901537f367c3c473376e4106abc72e01a8fc25b1cb6ed9c37e8c/mxnet_cu101-1.7.0-py2.py3-none-manylinux2014_x86_64.whl (846.0MB)\n",
            "\u001b[K     |███████████████████████████████▌| 834.1MB 1.2MB/s eta 0:00:10tcmalloc: large alloc 1147494400 bytes == 0x556026eac000 @  0x7f1e958f9615 0x555fed7e7cdc 0x555fed8c752a 0x555fed7eaafd 0x555fed8dbfed 0x555fed85e988 0x555fed8594ae 0x555fed7ec3ea 0x555fed85e7f0 0x555fed8594ae 0x555fed7ec3ea 0x555fed85b32a 0x555fed8dce36 0x555fed85a853 0x555fed8dce36 0x555fed85a853 0x555fed8dce36 0x555fed85a853 0x555fed8dce36 0x555fed85a853 0x555fed7ec30a 0x555fed85a60e 0x555fed8597ad 0x555fed7ec3ea 0x555fed85a3b5 0x555fed7ec30a 0x555fed85a3b5 0x555fed8594ae 0x555fed7ec3ea 0x555fed85b32a 0x555fed8594ae\n",
            "\u001b[K     |████████████████████████████████| 846.0MB 21kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101==1.7.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101==1.7.0) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (1.24.3)\n",
            "Installing collected packages: graphviz, mxnet-cu101\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu101-1.7.0\n",
            "Collecting gluoncv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/4c/cf840e62f66be8e258e5c3a8197d858daeb8b34af7b5ed4ac62b40bb2770/gluoncv-0.10.3-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.2.2)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/68/33/cb524f4de298509927b90aa5ee34767b9a2b93e663cf354b2a3efa2b4acd/portalocker-2.3.0-py2.py3-none-any.whl\n",
            "Collecting autocfg\n",
            "  Downloading https://files.pythonhosted.org/packages/95/f9/74e0a42cbc6d871c92288806e7812c7d2628c2a06557930dbab0a17438d2/autocfg-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from gluoncv) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.7/dist-packages (from gluoncv) (7.1.2)\n",
            "Collecting yacs\n",
            "  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->gluoncv) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->gluoncv) (1.15.0)\n",
            "Installing collected packages: portalocker, autocfg, yacs, gluoncv\n",
            "Successfully installed autocfg-0.0.8 gluoncv-0.10.3 portalocker-2.3.0 yacs-0.1.8\n",
            "Requirement already satisfied: gluoncv[full] in /usr/local/lib/python3.7/dist-packages (0.10.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gluoncv[full]) (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv[full]) (4.1.2.30)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gluoncv[full]) (1.1.5)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from gluoncv[full]) (0.1.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gluoncv[full]) (2.23.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from gluoncv[full]) (2.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gluoncv[full]) (3.13)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gluoncv[full]) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gluoncv[full]) (3.2.2)\n",
            "Requirement already satisfied: autocfg in /usr/local/lib/python3.7/dist-packages (from gluoncv[full]) (0.0.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gluoncv[full]) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gluoncv[full]) (4.41.1)\n",
            "Requirement already satisfied: cython; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from gluoncv[full]) (0.29.23)\n",
            "Collecting tensorboardx; extra == \"full\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/36/2b147652c40c3a858efa0afbf7b8236fae968e88ff530511a4cfa299a506/tensorboardX-2.3-py2.py3-none-any.whl (124kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 8.0MB/s \n",
            "\u001b[?25hCollecting autogluon.core; extra == \"full\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/4d/6e8e1eb195aa09c4f62dab87a4ff1d7cb5964369606e4fe91af0bf9c5ffa/autogluon.core-0.2.0-py3-none-any.whl (334kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 42.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycocotools; extra == \"full\" in /usr/local/lib/python3.7/dist-packages (from gluoncv[full]) (2.0.2)\n",
            "Collecting decord; extra == \"full\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/79/936af42edf90a7bd4e41a6cac89c913d4b47fa48a26b042d5129a9242ee3/decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6MB)\n",
            "\u001b[K     |████████████████████████████████| 13.6MB 33.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gluoncv[full]) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->gluoncv[full]) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv[full]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv[full]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv[full]) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv[full]) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv[full]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv[full]) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv[full]) (2.4.7)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardx; extra == \"full\"->gluoncv[full]) (3.12.4)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/de/807c75923e84530b8a94003d761bcea33ebd5469b3d56c1141208360f39f/boto3-1.17.101-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 55.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core; extra == \"full\"->gluoncv[full]) (1.3)\n",
            "Requirement already satisfied: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core; extra == \"full\"->gluoncv[full]) (5.1.1)\n",
            "Collecting ConfigSpace==0.4.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/c3/3c21e8d82a639fd821f538e6d7f830b654a6ce1fe52644be1a67f323f707/ConfigSpace-0.4.18.tar.gz (950kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 22.7MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dill==0.3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/d6/79f40d230895fa1ce3b6af0d22e0ac79c65175dc069c194b79cc8e05a033/dill-0.3.3-py2.py3-none-any.whl (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.8MB/s \n",
            "\u001b[?25hCollecting scikit-learn<0.25,>=0.23.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/eb/a48f25c967526b66d5f1fa7a984594f0bf0a5afafa94a8c4dbc317744620/scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core; extra == \"full\"->gluoncv[full]) (0.8.4)\n",
            "Collecting paramiko>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/19/124e9287b43e6ff3ebb9cdea3e5e8e88475a873c05ccdf8b7e20d2c4201e/paramiko-2.7.2-py2.py3-none-any.whl (206kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 55.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dask>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core; extra == \"full\"->gluoncv[full]) (2.12.0)\n",
            "Collecting distributed>=2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/03/104c2cb8f498165da0037fbe76581678027ea2722bac2775f04aaeafef65/distributed-2021.6.2-py3-none-any.whl (722kB)\n",
            "\u001b[K     |████████████████████████████████| 727kB 23.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools; extra == \"full\"->gluoncv[full]) (57.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->gluoncv[full]) (1.15.0)\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.0MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/76/f67a56460eba1997dd89b6b34b68150da1cf8cba0f5161cc4326383b4240/botocore-1.20.101-py2.py3-none-any.whl (7.7MB)\n",
            "\u001b[K     |████████████████████████████████| 7.7MB 33.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core; extra == \"full\"->gluoncv[full]) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25,>=0.23.2->autogluon.core; extra == \"full\"->gluoncv[full]) (1.0.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Collecting bcrypt>=3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/70/6d218afbe4c73538053c1016dd631e8f25fffc10cd01f5c272d7acf3c03d/bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 12.0MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/57/2f5e6226a674b2bcb6db531e8b383079b678df5b10cdaa610d6cf20d77ba/PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 43.3MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 43.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core; extra == \"full\"->gluoncv[full]) (2.4.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core; extra == \"full\"->gluoncv[full]) (0.11.1)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core; extra == \"full\"->gluoncv[full]) (2.0.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core; extra == \"full\"->gluoncv[full]) (5.4.8)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core; extra == \"full\"->gluoncv[full]) (1.7.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core; extra == \"full\"->gluoncv[full]) (7.1.2)\n",
            "Collecting cloudpickle>=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core; extra == \"full\"->gluoncv[full]) (1.0.2)\n",
            "Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core; extra == \"full\"->gluoncv[full]) (1.14.5)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core; extra == \"full\"->gluoncv[full]) (1.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core; extra == \"full\"->gluoncv[full]) (2.20)\n",
            "Building wheels for collected packages: ConfigSpace\n",
            "  Building wheel for ConfigSpace (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.18-cp37-cp37m-linux_x86_64.whl size=2879827 sha256=3950f1e0ec47c18f082ea4fe1261e85fff662f18d46eb70740bdb4cc5c105fca\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/ea/40/d93931850f700427db0a84180829c709d30484c9475040c7bd\n",
            "Successfully built ConfigSpace\n",
            "\u001b[31mERROR: multiprocess 0.70.12.2 has requirement dill>=0.3.4, but you'll have dill 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: distributed 2021.6.2 has requirement dask==2021.06.2, but you'll have dask 2.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.20.101 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: autogluon-core 0.2.0 has requirement scipy<1.7,>=1.5.4, but you'll have scipy 1.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboardx, jmespath, botocore, s3transfer, boto3, ConfigSpace, dill, threadpoolctl, scikit-learn, bcrypt, pynacl, cryptography, paramiko, cloudpickle, distributed, autogluon.core, decord\n",
            "  Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "Successfully installed ConfigSpace-0.4.18 autogluon.core-0.2.0 bcrypt-3.2.0 boto3-1.17.101 botocore-1.20.101 cloudpickle-1.6.0 cryptography-3.4.7 decord-0.6.0 dill-0.3.3 distributed-2021.6.2 jmespath-0.10.0 paramiko-2.7.2 pynacl-1.4.0 s3transfer-0.4.2 scikit-learn-0.24.2 tensorboardx-2.3 threadpoolctl-2.1.0\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF1Bdsxw9MrV"
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import argparse, time, logging, os, sys, math\n",
        "\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "import gluoncv as gcv\n",
        "from mxnet import gluon, nd, init, context\n",
        "from mxnet import autograd as ag\n",
        "from mxnet.gluon import nn\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "\n",
        "from gluoncv.data.transforms import video\n",
        "from gluoncv.data import VideoClsCustom\n",
        "from gluoncv.model_zoo import get_model\n",
        "from gluoncv.utils import makedirs, LRSequential, LRScheduler, split_and_load, TrainingHistory\n",
        "from gluoncv.utils.filesystem import try_import_decord\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, roc_curve, RocCurveDisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipTT7kl-_Oi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9fab880-6543-4ddf-8541-55c8c3c49151"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFtmvLRxBl4F"
      },
      "source": [
        "## 2. Defining a Custom [`DataLoader`](https://github.com/dmlc/gluon-cv/blob/master/gluoncv/data/kinetics400/classification.py) to Load the Custom Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwJgfa_DKooF"
      },
      "source": [
        "GluonCV allows the user to specify the custom dataset by means of a file `train.txt`, in which the user specifies the label of each of the videos that are to be used for training. Based on this file, class `VideoClsCustom` generates a customized data loader that can be used for later fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USR6lMGhLA18"
      },
      "source": [
        "video_location = '/content/gdrive/MyDrive/Computer Vision Group Assignment/Computer Vision Group Assignment/Footage/Raw_Data_computer_Vision'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNe5HUVUBtGb",
        "outputId": "ebaddb51-80ce-4119-c377-309d2930f0e4"
      },
      "source": [
        "num_gpus = 1\n",
        "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
        "transform_train = video.VideoGroupTrainTransform(size=(224, 224), scale_ratios=[1.0, 0.8], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "per_device_batch_size = 5\n",
        "num_workers = 0\n",
        "batch_size = per_device_batch_size * num_gpus\n",
        "\n",
        "train_dataset = VideoClsCustom(root=os.path.expanduser(video_location),\n",
        "                               setting=os.path.expanduser(video_location + '/train.txt'),\n",
        "                               train=True,\n",
        "                               new_length=32,\n",
        "                               transform=transform_train,\n",
        "                               video_loader=True,\n",
        "                               use_decord=True)\n",
        "print('Load %d training samples.' % len(train_dataset))\n",
        "train_data = gluon.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                   shuffle=True, num_workers=num_workers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load 30 training samples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_RrlgN6WN9m"
      },
      "source": [
        "The same can be done with a test dataset, to be used to properly tune the model's hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO_Am2r8WTEW",
        "outputId": "ee0deb5e-f4b9-4232-9e67-a217ee85d0cc"
      },
      "source": [
        "test_dataset = VideoClsCustom(root=os.path.expanduser(video_location),\n",
        "                               setting=os.path.expanduser(video_location + '/test.txt'),\n",
        "                               train=False,\n",
        "                               new_length=32,\n",
        "                               transform=transform_train,\n",
        "                               video_loader=True,\n",
        "                               use_decord=True)\n",
        "print('Load %d testing samples.' % len(test_dataset))\n",
        "test_data = gluon.data.DataLoader(test_dataset, batch_size=10,\n",
        "                                   shuffle=True, num_workers=num_workers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load 10 testing samples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvrnrIEeC9a3"
      },
      "source": [
        "## 3. Defining a Custom Net Architecture for Classification\n",
        "\n",
        "The network architecture to be employed adds a single fully-connected layer to the pre-trained model. This dense layer is the one in charge of translating the action detection from within 400 categories to the particular task of detecting violent behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anQhEH4GCqXz",
        "outputId": "588a06ee-faaa-47a2-9d5f-51088c6faf3a"
      },
      "source": [
        "net = get_model(name='i3d_resnet50_v1_custom', nclass=2)\n",
        "net.collect_params().reset_ctx(ctx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2_weight is done with shape:  (64, 3, 5, 7, 7)\n",
            "batchnorm2_gamma is done with shape:  (64,)\n",
            "batchnorm2_beta is done with shape:  (64,)\n",
            "batchnorm2_running_mean is done with shape:  (64,)\n",
            "batchnorm2_running_var is done with shape:  (64,)\n",
            "layer1_0_conv0_weight is done with shape:  (64, 64, 3, 1, 1)\n",
            "layer1_0_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_0_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_0_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_0_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_0_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer1_downsample_conv0_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_downsample_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_beta is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer1_1_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
            "layer1_1_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_1_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_1_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_1_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_1_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer1_2_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
            "layer1_2_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_2_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_2_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_2_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_2_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer2_0_conv0_weight is done with shape:  (128, 256, 3, 1, 1)\n",
            "layer2_0_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_0_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_0_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_0_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_0_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_downsample_conv0_weight is done with shape:  (512, 256, 1, 1, 1)\n",
            "layer2_downsample_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_beta is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer2_1_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
            "layer2_1_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_1_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_1_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_1_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_1_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_2_conv0_weight is done with shape:  (128, 512, 3, 1, 1)\n",
            "layer2_2_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_2_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_2_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_2_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_2_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_3_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
            "layer2_3_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_3_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_3_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_3_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_3_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer3_0_conv0_weight is done with shape:  (256, 512, 3, 1, 1)\n",
            "layer3_0_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_0_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_0_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_0_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_0_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_downsample_conv0_weight is done with shape:  (1024, 512, 1, 1, 1)\n",
            "layer3_downsample_batchnorm0_gamma is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_beta is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_running_mean is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_running_var is done with shape:  (1024,)\n",
            "layer3_1_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_1_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_1_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_1_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_1_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_1_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_2_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
            "layer3_2_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_2_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_2_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_2_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_2_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_3_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_3_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_3_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_3_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_3_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_3_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_4_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
            "layer3_4_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_4_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_4_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_4_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_4_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_5_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_5_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_5_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_5_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_5_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_5_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer4_0_conv0_weight is done with shape:  (512, 1024, 1, 1, 1)\n",
            "layer4_0_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_0_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_0_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_0_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_0_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_running_var is done with shape:  (2048,)\n",
            "layer4_downsample_conv0_weight is done with shape:  (2048, 1024, 1, 1, 1)\n",
            "layer4_downsample_batchnorm0_gamma is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_beta is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_running_mean is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_running_var is done with shape:  (2048,)\n",
            "layer4_1_conv0_weight is done with shape:  (512, 2048, 3, 1, 1)\n",
            "layer4_1_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_1_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_1_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_1_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_1_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_running_var is done with shape:  (2048,)\n",
            "layer4_2_conv0_weight is done with shape:  (512, 2048, 1, 1, 1)\n",
            "layer4_2_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_2_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_2_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_2_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_2_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_running_var is done with shape:  (2048,)\n",
            "dense2_weight is skipped with shape:  (2, 2048)\n",
            "dense2_bias is skipped with shape:  (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n8nEOvaGKFx"
      },
      "source": [
        "## 4. Training\n",
        "Now that the pre-trained model has been loaded, let's proceed to prepare and carry out the fine-tuning of the additional classifier layers.\n",
        "\n",
        "First, let's set all relevant training parameters. Note that SoftMax is used as a loss function, since this is a classifier task, and accuracy is employed as a performance metric. This last selection is valid since the classes in the custom dataset are balanced.\n",
        "\n",
        "Note that all of these hyperparameters are selected based on their effect on the test set. A series of tuning trainings have been carried out in order to select the learning rate, its rate of decay, and the epochs at which it decays. In order to select the number of epochs for training, the point at which the accuracy of the test set diverges with respect to the accuracy of the training set is selected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSwQBQyVDhMu"
      },
      "source": [
        "# Learning rate decay factor\n",
        "lr_decay = 0.1\n",
        "# Epochs where learning rate decays\n",
        "lr_decay_epoch = [10, 20, 30]\n",
        "\n",
        "# Stochastic gradient descent\n",
        "optimizer = 'sgd'\n",
        "# Set parameters\n",
        "optimizer_params = {'learning_rate': 0.005, 'wd': 0.0001, 'momentum': 0.9}\n",
        "\n",
        "# Define our trainer for net\n",
        "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgTFtmzfGdKe"
      },
      "source": [
        "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-gi71T-Ge9b"
      },
      "source": [
        "train_metric = mx.metric.Accuracy()\n",
        "test_metric = mx.metric.Accuracy()\n",
        "train_history = TrainingHistory(['training-acc', 'testing-acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAaqIxt2G92Y"
      },
      "source": [
        "Now, let's carry out the training following the specified parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Tfb4EzpGg0q",
        "outputId": "867a23e3-ea0c-4631-92e6-9f65f27f013b"
      },
      "source": [
        "epochs = 8\n",
        "lr_decay_count = 0\n",
        "test_accuracy = []\n",
        "train_accuracy = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    tic = time.time()\n",
        "    train_metric.reset()\n",
        "    train_loss = 0\n",
        "\n",
        "    # Learning rate decay\n",
        "    if epoch == lr_decay_epoch[lr_decay_count]:\n",
        "        trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
        "        lr_decay_count += 1\n",
        "\n",
        "    # Loop through each batch of training data\n",
        "    for i, batch in enumerate(train_data):\n",
        "        # Extract data and label\n",
        "        data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "        label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "        # AutoGrad\n",
        "        with ag.record():\n",
        "            output = []\n",
        "            for _, X in enumerate(data):\n",
        "                X = X.reshape((-1,) + X.shape[2:])\n",
        "                pred = net(X)\n",
        "                output.append(pred)\n",
        "            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n",
        "\n",
        "        # Backpropagation\n",
        "        for l in loss:\n",
        "            l.backward()\n",
        "\n",
        "        # Optimize\n",
        "        trainer.step(batch_size)\n",
        "\n",
        "        # Update metrics\n",
        "        train_loss += sum([l.mean().asscalar() for l in loss])\n",
        "        train_metric.update(label, output)\n",
        "\n",
        "        if i == 100:\n",
        "            break\n",
        "\n",
        "    name, acc_train = train_metric.get()\n",
        "    # Update history and print metrics\n",
        "    train_accuracy.append(acc_train)\n",
        "    print('[Epoch %d] train=%f loss=%f time: %f' %\n",
        "        (epoch, acc_train, train_loss / (i+1), time.time()-tic))\n",
        "    \n",
        "    # Loop through each batch of test data\n",
        "    for i, batch in enumerate(test_data):\n",
        "        # Extract data and label\n",
        "        data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "        label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "        output = []\n",
        "        for _, X in enumerate(data):\n",
        "            X = X.reshape((-1,) + X.shape[2:])\n",
        "            pred = net(X)\n",
        "            output.append(pred)\n",
        "\n",
        "        test_metric.update(label, output)\n",
        "\n",
        "    name, acc_test = test_metric.get()\n",
        "    # Update history and print metrics\n",
        "    test_accuracy.append(acc_test)\n",
        "\n",
        "    train_history.update([acc_train, acc_test])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0] train=0.466667 loss=0.714402 time: 14.610803\n",
            "[Epoch 1] train=0.733333 loss=0.544539 time: 13.665175\n",
            "[Epoch 2] train=0.733333 loss=0.434229 time: 13.857138\n",
            "[Epoch 3] train=0.900000 loss=0.236532 time: 14.246646\n",
            "[Epoch 4] train=0.833333 loss=0.326405 time: 13.527847\n",
            "[Epoch 5] train=0.966667 loss=0.110094 time: 13.089769\n",
            "[Epoch 6] train=0.900000 loss=0.269472 time: 13.829254\n",
            "[Epoch 7] train=0.900000 loss=0.180924 time: 13.414001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "hbO7NH2wZb_t",
        "outputId": "b830eb4c-07ab-43dd-ff64-3f4f5778427b"
      },
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_accuracy, label='Train Accuracy')\n",
        "plt.plot(test_accuracy, label='Test Accuracy')\n",
        "plt.legend(fontsize=12)\n",
        "plt.title('Train and Test Accuracies during Training', fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMu_AvlxFNMt"
      },
      "source": [
        "## 5. Model Evaluation with a Validation Set\n",
        "Now that a model with an adequate set of hyperparameters has been trained, it is time to evaluate its performance on a separate validation set of videos. Thus, all we need is to load, preprocess, and predict on this new group of data samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zcKuz5NFQk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ce6b85-7814-48d2-a439-0d0fe71a815a"
      },
      "source": [
        "decord = try_import_decord()\n",
        "\n",
        "test_folder = '/content/gdrive/MyDrive/Computer Vision Group Assignment/Computer Vision Group Assignment/Footage/Test Data/'\n",
        "test_video_files = os.listdir(test_folder)\n",
        "\n",
        "classes=[\"0 - Safe\",\"1 - Violent\"]\n",
        "topK = 2\n",
        "threshold = 0.2\n",
        "predictions = []\n",
        "probabilities = []\n",
        "true_labels = [0, 1, 0, 1, 0, 1, 0, 1]\n",
        "\n",
        "for file_idx in range(len(test_video_files)):\n",
        "  video_fname = test_folder + test_video_files[file_idx]\n",
        "  vr = decord.VideoReader(video_fname)\n",
        "  frame_id_list = range(0, 64, 2)\n",
        "  video_data = vr.get_batch(frame_id_list).asnumpy()\n",
        "  clip_input = [video_data[vid, :, :, :] for vid, _ in enumerate(frame_id_list)]\n",
        "\n",
        "  transform_fn = video.VideoGroupValTransform(size=(224, 224), mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "  clip_input = transform_fn(clip_input)\n",
        "  clip_input = np.stack(clip_input, axis=0)\n",
        "  clip_input = clip_input.reshape((-1,) + (32, 3, 224, 224))\n",
        "  clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))\n",
        "  print('Video data is readed and preprocessed.')\n",
        "\n",
        "  # Running the prediction\n",
        "  pred = net(nd.array(clip_input,  ctx = mx.gpu(0)))\n",
        "\n",
        "  # Defining classes\n",
        "  ind = nd.topk(pred, k=topK)[0].astype('int')\n",
        "\n",
        "  # Obtaining probability and prediction\n",
        "  prob_violent = nd.softmax(pred)[0][ind[1]].asscalar()\n",
        "  probabilities.append(prob_violent)\n",
        "  if prob_violent > threshold:\n",
        "    predictions.append(1)\n",
        "  else:\n",
        "    predictions.append(0)\n",
        "  \n",
        "  print('The input video clip named '+test_video_files[file_idx]+' is classified to be')\n",
        "  for i in range(topK):\n",
        "    print('\\t[%s], with probability %.3f.'%\n",
        "          (classes[ind[i].asscalar()], nd.softmax(pred)[0][ind[i]].asscalar()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video data is readed and preprocessed.\n",
            "The input video clip named video_001_1.mp4 is classified to be\n",
            "\t[0 - Safe], with probability 0.995.\n",
            "\t[1 - Violent], with probability 0.005.\n",
            "Video data is readed and preprocessed.\n",
            "The input video clip named video_002_1.mp4 is classified to be\n",
            "\t[0 - Safe], with probability 0.783.\n",
            "\t[1 - Violent], with probability 0.217.\n",
            "Video data is readed and preprocessed.\n",
            "The input video clip named video_003_1.mp4 is classified to be\n",
            "\t[0 - Safe], with probability 0.998.\n",
            "\t[1 - Violent], with probability 0.002.\n",
            "Video data is readed and preprocessed.\n",
            "The input video clip named video_004_1.mp4 is classified to be\n",
            "\t[1 - Violent], with probability 0.508.\n",
            "\t[0 - Safe], with probability 0.492.\n",
            "Video data is readed and preprocessed.\n",
            "The input video clip named Video_001_0.mp4 is classified to be\n",
            "\t[0 - Safe], with probability 0.728.\n",
            "\t[1 - Violent], with probability 0.272.\n",
            "Video data is readed and preprocessed.\n",
            "The input video clip named video_002_0.mp4 is classified to be\n",
            "\t[0 - Safe], with probability 0.846.\n",
            "\t[1 - Violent], with probability 0.154.\n",
            "Video data is readed and preprocessed.\n",
            "The input video clip named video_003_0.mp4 is classified to be\n",
            "\t[0 - Safe], with probability 0.588.\n",
            "\t[1 - Violent], with probability 0.412.\n",
            "Video data is readed and preprocessed.\n",
            "The input video clip named video_004_0.mp4 is classified to be\n",
            "\t[0 - Safe], with probability 0.627.\n",
            "\t[1 - Violent], with probability 0.373.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3arqCjNwIE5"
      },
      "source": [
        "Now let us take a look at the model's performance based on the validation set. Since the classes in the set are balanced, it is adequate to examine the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOyTDPxOu7oI",
        "outputId": "0d2911f2-4384-46ef-9365-72165d012294"
      },
      "source": [
        "print(f\"The model's accuracy on the validation data set is {accuracy_score(true_labels, predictions) * 100:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model's accuracy on the validation data set is 62.500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3dNmCICwZ3u"
      },
      "source": [
        "These results are scracely better than a random guess! \n",
        "In any case, let's look at the ROC curve based on this validation set, since it is necessary to select a probability threshold to classify data samples as violent. Note that for a safe real implementation of this code, it would be preferrable to minimize false negatives at the cost of a larger amount of false posiitives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "s_ItKOkmv412",
        "outputId": "2498454c-0dfc-4a7a-cb0f-d24392408656"
      },
      "source": [
        "fpr, tpr,_ = roc_curve(true_labels, probabilities)\n",
        "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plhmSLYFyCMq"
      },
      "source": [
        "These results are not too elucidating, since the number of data samples in the validation set may be too scarce. This explains why the curve advances in a set-wise manner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tqa_AQh3ydqX"
      },
      "source": [
        "## 6. Further Work\n",
        "\n",
        "Although the application of this model may save a lot of time and money in a successful implementation, much more needs to be explored to bring about model with a performance that makes its use viable.\n",
        "\n",
        "In particular, the generation of an optimum dataset has been constrained by a number of factors:\n",
        "*   On the one hand, the extent of this dataset has been limited by the available amount of time. Given that no standardized method for extraction of videos has been implemented, since the method varies accross particular equipments, this process proved to be somewhat time-consuming.\n",
        "*   Moreover, the availability of representative data samples has also proven to be limited. Given that the main source for extracting data samples has been YouTube, it has been much easier to find CCTV recordings containing violent behavior than to find those with mundane actions. As a result, many of the data samples labelled with 'Non-Violent' come from either the few videos with such content that have been found, or from short interludes of violent recordings in which violent actions are not visible.\n",
        "* Lastly, it is worth considering to what extent does the presence of multiple people in a recording, each performing a different action, hinders the model's prediction. Taking the Kinetics 400 dataset, it is possible to see that most videos show a limited number of people, all carrying out the same activity. This difference in the nature of data samples may be solvable with a more refined dataset, but may cause obstacles when acoming to a realistic application.\n",
        "\n",
        "Some other possible areas to work on in future developments of this project involve:\n",
        "* Examining how a larger dataset affects the hyperparameter selection based on the test set.\n",
        "* Examining how a larger dataset affects the model's evaluation based on the validation set, as well as the selection of a probability threshold based on which to predict.\n",
        "* Gaining more experience with MXNET, since many obstacles in this project have been found due to the limited knowledge of this library.\n"
      ]
    }
  ]
}